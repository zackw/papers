<!doctype html>
<html><head>
  <meta charset="utf-8">
  <title>Website Fingerprinting Attacks on Low-Latency Mix Networks</title>
  <link rel="stylesheet" href="r/fonts.css">
  <link rel="stylesheet" href="r/prez-cylab.css">
</head>
<body>

<section class="title">
  <hgroup>
    <h1>Website Fingerprinting Attacks on Low-Latency Mix Networks</h1>
    <h2>Zachary Weinberg</h2>
  </hgroup>
  <p style="position:absolute;bottom:5px;left:5px"><img src="r/cylab.svg"
  alt="Carnegie Mellon University: CyLab"></p>
</section>

<section>
  <object data="tor-background-1.svg"></object>
</section>

<section>
  <object data="tor-background-2.svg"></object>
</section>

<section>
  <object data="tor-background-3.svg"></object>
</section>

<section>
  <img src="waterfall-4.png">
</section>

<section>
  <img src="waterfall-2.png">
</section>

<section>
  <object data="tor-trace.svg"></object>
</section>

<section>
  <object data="tor-traces.svg"></object>
</section>

<section>
  <h2>Liberatore and Levine (2006)</h2>
  <ul>
    <li>Most-frequently-visited 2000 sites from their department,
    one-month sample</li>
    <li>Train and test on front page of each</li>
    <li>Seek to minimize size of stored fingerprints
    <li>Two classifiers: naive Bayes, Jaccard coefficient
  </ul>
</section>

<section>
  <h2>Naive Bayes</h2>
  <ul>
    <li>Categorizes input into classes \(C_i\) based on attributes \(A_j\)
    <li>Naivete = assume all attributes are uncorrelated
    <li>Apply Bayes’ theorem: probability that an observed set of
        attributes \(\bar{A}\) belongs to class \(C_i\) is
        $$\Pr(C_i\mid\bar{A}) \propto \Pr(C_i) \prod_{A_j\in \bar{A}}
        \Pr(A_j\mid C_i)$$
    <li>Choose most probable class from all available
  </ul>
</section>

<section>
  <h2>Overall packet length probability</h2>
  <figure>
    <object data="ll-packet-length-overall.svg"></object>
    <figcaption>reproduced from Liberatore and Levine 2006</figcaption>
  </figure>
</section>

<section>
  <h2>Jaccard coefficient</h2>
  <p>Given two sets \(X\) and \(Y\), Jaccard's coefficient \(S\) is
    $$S(X,Y) = \frac{|X\cap Y|}{|X\cup Y|}$$</p>
  <p>To classify a set \(X\), just find the class representative \(Y\)
    that it is most similar to.
</section>

<section>
  <h2>Overall packet length occurrence prob.</h2>
  <figure>
    <object data="ll-packet-length-occurrence.svg"></object>
    <figcaption>reproduced from Liberatore and Levine 2006</figcaption>
  </figure>
</section>

<section>
  <h2>Accuracy by world size</h2>
  <figure>
    <object data="ll-accuracy-by-worldsize.svg"></object>
    <figcaption>reproduced from Liberatore and Levine 2006</figcaption>
  </figure>
</section>

<section>
  <h2>Accuracy by training set size</h2>
  <figure>
    <object data="ll-accuracy-by-training.svg"></object>
    <figcaption>reproduced from Liberatore and Levine 2006</figcaption>
  </figure>
</section>

<section>
  <h2>Accuracy by time</h2>
  <figure>
    <object data="ll-accuracy-by-time.svg"></object>
    <figcaption>reproduced from Liberatore and Levine 2006</figcaption>
  </figure>
</section>

<section>
  <h2>Cai et al. 2012</h2>
  <ul>
    <li>Retest some now-standard techniques (naive Bayes, ad hoc SVM)
    <li>Twist of their own: edit distance as SVM kernel
    <li>Using ordered sequences of packet lengths
    <li>Generalize from front pages to entire sites with hidden Markov
      models
    <li>Alexa top 100 for front-page experiments
    <li>Facebook and IMDB for entire-site experiments
  </ul>
</section>

<section>
  <h2>Support vector machine</h2>
  <figure>
    <img src="Svm_max_sep_hyperplane_with_margin.png">
    <figcaption><a href="https://commons.wikimedia.org/wiki/File:Svm_max_sep_hyperplane_with_margin.png">Diagram from Wikimedia Commons</a></figcaption>
  </figure>
</section>

<section>
  <h2>SVM with kernel transformation</h2>
  <figure>
    <img src="Kernel_Machine.png">
    <figcaption><a href="https://commons.wikimedia.org/wiki/File:Kernel_Machine.png">Diagram from Wikimedia Commons</a></figcaption>
  </figure>
</section>

<section>
  <h2>Edit distance (Damerau-Levenshtein)</h2>
  <ul>
    <li>Count number of single-symbol insertions, deletions, and
      substitutions, and adjacent-symbol transpositions, required to
      transform string \(t\) into string \(u\)
    <li>Satisfies all requirements of a distance metric
    <li>For use in SVM, define kernel transformation
        $$K(t, u) = e^{-\gamma
        \left(\frac{d(t,u)}{\min(|t|,|u|)}\right)^2}$$
        where \(d(t,u)\) is raw edit distance, \(\gamma\) a tuning
        parameter
    <li>Cai claim: good match for real network and HTTP-level behavior
  </ul>
</section>

<section>
  <h2>Front-page classification accuracy</h2>
  <figure>
    <object data="cai-accuracy-by-worldsize.svg"></object>
    <figcaption>reproduced from Cai et al. 2012</figcaption>
  </figure>
</section>

<section>
  <h2>Hidden Markov Models</h2>
</section>

<section>
  <h2>Entire-site visit detection</h2>
  <figure>
    <object data="cai-markov.svg"></object>
    <figcaption>reproduced from Cai et al. 2012</figcaption>
  </figure>
</section>

<section>
  <h2>Weinberg et al. 2012</h2>
  <ul>
    <li>Hypothesis: country scale fingerprinting highly resource constrained
    <li>Goal: minimize resource requirements at detection time
    <li>Only tried to detect visits to Alexa top ten
    <li>Competitive accuracy with simple sliding-window classifier:
      $$\begin{multline}\log\Pr\bigl[\{u_i,d_i\}\;\text{is }\textit{site}\bigr] = \\
        \sum_{i=1}^n \log\Pr\bigl[U_i=u_i\bigr] + \sum_{i=1}^n \log\Pr\bigl[D_i=d_i\bigr]\end{multline}$$
  </ul>
</section>

<section>
  <h2>Accuracy (one site)</h2>
  <figure>
    <object data="facebook-detect.svg"></object>
    <figcaption>reproduced from Weinberg et al. 2012</figcaption>
  </figure>
</section>

<section>
  <img src="elephant.png">
</section>

<section>
  <h2>Recap: accuracies</h2>
  <table>
    <tr><th>Paper<th>Attack<th>Pages<th>Success
    <tr><td rowspan="2">Liberatore<td>Naive Bayes<td>2000<td>70%
    <tr><td>Jaccard<td>2000<td>63%
    <tr class="bgroup"><td rowspan="3">Cai<td>DLSVM<td>100<td>85%
    <tr><td>Ad hoc SVM<td>100<td>67%
    <tr><td>Naive Bayes<td>100<td>5%
    <tr class="bgroup"><td>Weinberg<td>Log-probability<td>60<td>98%
    (binary)
  </table>
</section>

<section>
  <h2>Does fingerprinting <i>scale?</i></h2>
  <ul>
    <li>Not with accuracies below 99.999…%
    <li>Research to date: \(\le2000\) sites in test set
    <li>Entire global Web: \(\sim 10^9\) sites, at least \(10\times\) that pages
    <li>Fingerprinting for internet-scale “filtering” needs a false
    positive rate below \(10^{-6}\) … while keeping false negatives
    down too
  </ul>
</section>

<section class="title">
  <hgroup>
    <h1>Questions?</h1>
  </hgroup>
</section>

<section></section>

<script src="r/prez.js"></script>
<script src="r/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>
