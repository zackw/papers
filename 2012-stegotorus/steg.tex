\section{Steganography}\label{s:steg}

In this section, we describe two proof-of-concept steganography
modules: one that duplicates the packet sizes and timings of encrypted
peer-to-peer protocols, and one that mimics HTTP.  These modules
illustrate the flexibility and feasibility of the StegoTorus
framework.  However, they are not expected to resist sophisticated,
targeted attacks that might be launched by a nation-state adversary.
To underscore this, for each module we also describe potential attacks
and the level of sophistication each requires.

More diverse and resilient modules are under development, both by us
and the larger community, as the arms race continues.  The StegoTorus
client can be configured to use whichever modules the adversary has
not yet blocked; therefore, ultimately, the adversary will have to
detect and block traffic generated by \emph{all} of the steganography
modules in order to block StegoTorus.

\subsection{Embed Module}

The \emph{embed} steganography module conceals Tor traffic within an
encrypted, peer-to-peer cover protocol, such as the popular Skype and
Ventrilo protocols for secure voice over IP.  (Ventrilo is not
strictly a peer-to-peer protocol, but its users typically set up their
own servers, so there is no small, stable set of server IPs that could
be whitelisted.)  Since the audio payload of each packet is encrypted,
we can substitute our own encrypted data without fear of payload
inspection.  This leaves cleartext headers, packet sizes, and
inter-packet timings as the characteristics visible to the censor.

\subsubsection{Packet Traces}

This module relies on a database of \emph{packet traces}, pre-recorded
sequences of packet sizes and timings from real sessions of the cover
protocol.  Client and server match the recorded packet sizes exactly,
and timings to the nearest millisecond.  If there is no data available
when a packet should be sent, they will fabricate padding-only blocks
to maintain the deception.

The server does not maintain its own database of traces; instead, the
client transmits its chosen trace to the server as a special control
message, immediately after link setup.  Some of these traces are
distributed with the software, but users are encouraged to capture
their own use of the cover protocol, so that the censor cannot block
StegoTorus by pattern-matching against the distributed set of traces.
(Packet timings seen by the client may or may not correspond to packet
timings as actually transmitted by the server.  For greater realism,
one should capture a trace from both ends, but we have not implemented
this yet.)

\smallskip\noindent\textbf{Potential Attacks:} Some VoIP protocols
permit an eavesdropping adversary to learn much about the speech being
transmitted, just from packet sizes and timings~\cite{a-foniks}.
Therefore, if traces are reused too often, the censor might become
suspicious of users apparently having the exact same conversation over
and over again.

\subsubsection{Application Headers}

The packet trace does not attempt to capture application headers, as
these may depend on the substituted contents.  Instead, the
\emph{embed} module includes emulation code for each potential cover
protocol.  Unfortunately, neither the Skype nor the Ventrilo protocol
has a public specification, necessitating reverse engineering.  To
date this has been done by hand, but we are investigating the
possibility of automating the
process~\cite{a-polyglot,a-discoverer,a-ctxtaware}.

\smallskip\noindent\textbf{Potential Attacks:} If the censor has
access to the true protocol specification for a protocol we have
reverse engineered, they may be able to detect deviations on our
part.

Even if the censor doesn't have this information, it might choose to
block \emph{all} apparent VoIP protocols, or all peer-to-peer traffic
that appears to contain encrypted data.  These are popular, but not
yet so popular that this would amount to “turning off the Internet,”
and there are plausible political cover stories for such actions by a
nation-state: preserving telephone revenue, combating copyright
infringement, etc.

\subsection{HTTP Module}

The \emph{HTTP} steganography module simulates unencrypted HTTP
traffic.  Since the censor can observe the overt content of this
module's traffic, and protocol decoders for HTTP are ubiquitous, we
take care to mimic “real” browser and website behavior as accurately
as possible.

HTTP~\cite{s-http} follows a strict pattern: the client sends a
\emph{request}, waits for the server to produce a \emph{response}, can
then send another request, and so on.  HTTP~1.1 allows the client to
send several requests in a row without waiting for responses
(“pipelining”) but this is rarely used, due to server
bugs~\cite{s-pipeline}.  Instead, clients achieve parallelism by
opening multiple connections to the same server.  Each request
contains a “method” (\textsc{get}, \textsc{post}, etc) that controls
what the server will do to prepare the response.

The \emph{HTTP} module also relies on a database of pre-recorded HTTP
requests and responses; we also refer to these as “traces.”  Like the
\emph{embed} module's traces, some are distributed with the program,
and users are encouraged to record their own.  Unlike \emph{embed},
requests and responses are not organized into a temporal sequence, and
client and server use independent databases.  However, the server
generates responses that are consistent with client requests; for
instance, if a client sends a request for a PDF document, the server
will produce a PDF covertext.

\subsubsection{Request Generator}

Normal HTTP client-to-server traffic consists almost entirely of
\textsc{get} requests.  Unfortunately, these provide very little space
to conceal our hiddentexts.  Here is a typical request template from
our database:

\begin{lstlisting}
GET /<uri> HTTP/1.1
Accept: text/html,application/xhtml+xml,
    application/xml;q=0.9,*/*;q=0.8
Accept-Encoding: gzip, deflate
Accept-Language: en-us,en;q=0.5
Connection: keep-alive
Host: <host>
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:10.0)
    Gecko/20100101 Firefox/10.0
Cookie: <cookie>
\end{lstlisting}

\noindent Nearly all of this is boilerplate that must be sent verbatim
in every request.  Data can be inserted at each position marked
\textitt{<\ldots>}, but it must be properly encoded.

At present we only store hiddentext in the \textitt{<uri>} and
\textitt{<cookie>} positions, which can carry arbitrary textual data.
We encode the binary chopper output in a modified \texttt{base64}
alphabet~\cite{s-base64} that avoids characters with special meaning
in URIs or cookies: `\texttt{+}' is replaced by `\texttt{-}',
`\texttt{/}' by `\texttt{\_}', and `\texttt{=}' by `\texttt{.}'.  We
then insert characters at random positions in the encoded string, to
make it look more like a genuine URI or cookie header: for URIs we
insert `\texttt{/}', for cookies we alternate between `\texttt{=}' and
`\texttt{;}'.

The \textitt{<host>} can theoretically also carry hiddentext, but with
more difficulty: \textitt{<host>} must have the form of a DNS hostname
or IP address~\cite{s-http}, and the censor could block HTTP
connections where it was not a registered hostname for the IP address
to which the client was connected.  Presently, we do not attempt this;
instead we do a reverse DNS lookup on the server's IP address, and use
the first reported name in every request to that address.

\smallskip\noindent\textbf{Potential Attacks:}
To the human eye, the HTTP request generator's URIs and cookies likely
look different from normal URIs or cookies.  The pattern of requests
that it generates is also potentially different from the pattern of
requests generated by a visit to a real website.  Hence, it would be
possible for an adversary to build a machine classifier that can make
the same judgment.  The cookie string we send changes on every
request, without the server sending back \texttt{Set-Cookie:}
directives; this could also be a distinguisher, as a real web browser
only changes cookies when instructed to.  If such attacks become
common, they we may be limited in our use of cookies as a carrier
channel.  More sophisticated cookie, URI, and request pattern
generation is also possible; Infranet~\cite{c-infranet}, for instance,
devotes some effort to this problem.  However, substantially more
overhead will be required.

The \texttt{User-Agent} header identifies the browser and operating
system in use.  If the same client IP address consistently produces
one user-agent, except during a handful of browsing sessions, that
handful might attract attention.  Generating a database of client
requests on each user's machine ensures that we generate user-agent
headers matching the browser that that user normally uses.

The censor may conduct active attacks by replaying HTTP requests; a
real web server would normally produce the same response, but
StegoTorus will not.  To mitigate this we could place an off-the-shelf
HTTP “accelerator” cache in front of the StegoTorus server so that,
for a short time, replayed requests would produce the same response as
the original.

\subsubsection{Response Generator}

HTTP responses begin with a few headers, similar to the ones shown
above, but offering even less space for hiddentext.  However, they
continue with a “response body” which is \emph{designed} to carry
arbitrary data.  That data typically conforms to some known file
format, which must be consistent with the contents of the request.  We
have developed response generators that embed StegoTorus hiddentexts
in three common file formats: JavaScript, PDF, and Flash.  These data
formats are complex enough to conceal hiddentexts easily, and
pervasive enough that blocking them would break far too many popular
websites to be politically tenable.  Generators for HTML and various
image, audio, and video formats are under development.

\smallskip\noindent\textbf{JavaScript Generator:} JavaScript is a
programming language, human-readable in its original form, but
frequently “minified” to reduce its size on the wire. Minification
involves removing all white space and replacing variable names with
shorter machine-generated identifiers.  There is an enormous volume of
JavaScript in use on the open web: 2.5\% of all bytes transferred by
HTTP in early 2009~\cite{a-res-traffic}.

This generator picks a response containing JavaScript, scans it for
identifiers and numbers, and replaces them with characters from the
hexadecimal encoding of the hiddentext.  To preserve syntactic validity,
the encoder will not change the first character of an identifier or a
number, and there is a blacklist of JavaScript keywords and built-in
functions that should not be replaced.  The decoder simply reverses
the process.  Our objective with this module is to produce syntactically
valid JavaScript that cannot be trivially detected by a parser.

\smallskip\noindent\textbf{PDF Generator:} PDF documents consist of a
sequence of “objects,” which define pages, images, fonts, and so on.
Many of these objects will normally be compressed, using the
ubiquitous “deflate” algorithm, to save space.  The PDF response
generator locates compressed objects within a PDF document from the
HTTP response database, and replaces their contents with our
hiddentexts.  Chopper output is incompressible, but we apply the
“deflate” transformation to it anyway, so that each modified object's
contents is still superficially what it ought to be.  The overall file
structure is adjusted to match.

\smallskip\noindent\textbf{SWF Generator:} Adobe (formerly Shockwave)
Flash is a format for vector-graphic animations, and is also
frequently used as a container for video.  Flash files consist of a
sequence of tagged data blocks, containing shapes, buttons, bitmaps,
ActionScript byte code, etc.~\cite{s-flash} Flash files may be
compressed (CWS) or uncompressed (FWS). In the more common CWS format,
the entire file (with the exception of a short initial header, but
including the block framing) is compressed with “deflate.”  The SWF
response generator uncompresses a template CWS file, replaces block
contents with encrypted data, and recompresses the result.

\smallskip\noindent\textbf{Potential Attacks:}
The HTTP response generator attempts to preserve the syntactic
validity of JavaScript, PDF and SWF files that it modifies.  However,
it does not attempt to preserve the semantics of JavaScript or the
original content of PDF or SWF.  Therefore, adversaries might be able
to detect the use of the present HTTP generator by attempting to
execute JavaScript, render PDF documents, or play back Flash
animations.  However, doing so at line rate on a border router would
be quite challenging.  The filter would have to extract HTTP response
bodies of interest, reassemble packets into streams, and then parse
and decode the contents of the file; all of these are expensive and
complicated operations.  Providing the appropriate execution
environment for JavaScript requires the adversary to assemble and
process all the data of the surrounding webpage, just as a browser
would.

Nonetheless, we do expect that if StegoTorus comes into wide use,
filtering routers will gain the ability to detect these simple
schemes.  In particular, a natural escalation of the arms race might
involve the use of cascading detectors, where a series of fast filters
select traffic to subject to more expensive analyses.  If this
happens, we would have to implement more sophisticated steganography.
